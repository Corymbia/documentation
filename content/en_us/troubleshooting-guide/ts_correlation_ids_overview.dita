<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_correlation_id">
 <title>Correlation IDs</title>
 <shortdesc>Eucalyptus 4.1 introduces <i>correlation IDs</i>, which are unique identifiers that
  allow a cloud administrator to track requests across Eucalyptus components.</shortdesc>
 <conbody>

  <p>One of the most difficult problems that many Eucalyptus administrators face is troubleshooting
   user requests across the distributed components that make up a Eucalyptus cloud. </p>
  <p>For example, when a cloud user tries to run an EBS-backed instance, this is the rough sequence
   of what's happening in the Eucalyptus cloud:</p>
  <ul>
   <li>The front end receives a <codeph>RunInstances</codeph> request, and checks the available back
    end resources (CPU, IP, Storage, etc) and the requested VM size.</li>
   <li>The front end commits the resource allocation and sends a <codeph>CreateVolume</codeph>
    request to the Storage Controller.</li>
   <li>When the volume containing the VM image is ready, the front end sends a
     <codeph>PrepareNetwork</codeph> request to the Cluster Controller, which then allocates an IP
    address in its managed network pool</li>
   <li>The <codeph>RunInstances</codeph> request is then passed to the Node Controller, which
    allocates a storage resource on its local disk, creates a iSCSI connection to the volume, and
    spins up the VM instance. </li>
  </ul>
  <p>There are many possible failure points in this sequence. For example, what happens when the
   Storage Controller rejects "CreateVolume" request because it could not find an available space in
   the SAN device? The admission control in step 1) can't rule out this because the front-end can't
   guarantee 100% time that its "view" of the backend resources matches with the latest status of
   the resources. While the so-called "Eventual consistency" makes the Eucalyptus highly scalable,
   it revenges its users with the frequent distributed failures that is difficult to troubleshoot.
   It is frustrating to Cloud Users who sees their pending VM goes to terminated without any clue.
   It is even more frustrating to the Cloud Admins who receives the complaints from its users but
   can't easily locate the source of the problem after parsing tens of distributed log files. Are
   you familiar with this situation? </p>
  <p><b>Correlating distributed actions to a user's request ID</b></p>
  <p> In AWS (and EUCA), every response from EC2 (and other AWS services) include a requestID
   element (http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-query-api.html). This is a
   unique ID to present to AWS to troubleshoot the request. In Eucalyptus, requestID element is also
   included in every message between components. In 4.1., we changed the format of the requestID
   between internal components to include the requestID that the user receives. The example below
   illustrates the example messages exchanged between various parties:</p>
  <p><codeblock><![CDATA[USER <-– RunInstances (0a26cd99-1db3-47da-8fce-e517d0c3c95a) –->    EUCA_FRONT_END  
EUCA_FRONT_END  <-- CreateVolume (0a26cd99-1db3-47da-8fce-e517d0c3c95a::c9c52f75-c853-4af5-8c26-5141fb4c3c48) --> STORAGE_CONTROLLER 
                <-- PrepareNetwork (0a26cd99-1db3-47da-8fce-e517d0c3c95a::aff235b2-8599-46b1-9d45-2e3005e00067) --> CLUSTER_CONTROLLER      
                <-- RunVmInstances (0a26cd99-1db3-47da-8fce-e517d0c3c95a::144c6edf-c89f-4a6f-b371-5339049d5847) --> NODE_CONTROLLER  
NODE_CONTROLLER <-- AttachVolume ( 0a26cd99-1db3-47da-8fce-e517d0c3c95a::bb29896d-f840-432c-8e0a-51bdd22cbe83) --> STORAGE_CONTROLLER]]></codeblock></p>
  <p>Because every message now contains a request ID that the Cloud User receives in the response,
   we can correlate the distributed component's actions to what Cloud User has requested initially.
   In the messages above, if the Node Controller fails to attach the EBS volume, the error message
   logged in Node Controller can have the originating request ID. </p>
  <p><b>Including request IDs in the distributed logs</b></p>
  <p> Each component of Eucalyptus writes logs that is (hopefully) helpful debugging a problem. In
   4.1., we introduce a new set of log files that contain the messages (only) associated with the
   user's requests. If the message arrived at the component triggers actions and write logs, the
   requestID from the message is logged in the same line with the debug message. For example, the
   following is the logs on NC: </p>
  <p>
   <codeblock>2014-12-10 14:12:04  INFO 000012097 doRunInstance            | [<b>0a26cd99-1db3</b>] [i-9290fc99] running instance cores=1 disk=5 memory=256 vlan=-1 net=-1 priMAC=d0:0d:92:90:fc:99 privIp=10.111.78.24 plat=linux kernel=(null) ramdisk=(null)
2014-12-10 14:12:04 DEBUG 000012097 vbr_legacy               | [<b>0a26cd99-1db3</b>] [i-9290fc99] VBR[0] type=ephemeral id=none dev=sdb size=3221225472 format=ext3 none
2014-12-10 14:12:04 DEBUG 000012097 change_state             | [<b>0a26cd99-1db3</b>] [i-9290fc99] state change for instance: Unknown -> Staging (Pending)
2014-12-10 14:12:04 DEBUG 000018029 startup_thread           | [<b>0a26cd99-1db3</b>] [i-9290fc99] spawning startup thread</codeblock>
  </p>
  <p> The characters in bold face are the correlation ID - the first 13 digits of the original
   request ID. This correlation ID is written into the log files used by the Eucalyptus cloud
   components. The cloud administrator can use this unique identifier to search the logs and track
   down any errors that happen across the distributed cloud components. </p>
  <p><b>Using LogTracker to gather and parse the distributed logs</b></p>
  <p> Although having the request ID in the log files is useful when debugging a user's problems, it
   still requires a quite effort to mine distribute logs to locate the source of the problem. To
   help alleviate this problem, we've introduced new tools to gather distributed Eucalyptus logs and
   search for messages with a request ID. </p>
  <p>The LogTracker tools are hosted at https://github.com/eucalyptus/logtrackers.</p>
  <p>In the following example, user with the account name "Bob" has tried but failed to run an
   instance. Using the logtracker tools, the administrator can track down Bob's request.</p>
  <p>First, use the <codeph>euca-req-history</codeph> command to find the request ID for Bob's
    <codeph>RunInstance</codeph> command:</p>
  <codeblock>[root@c-27 ~]# euca-req-history bob -n RunInstance
DATE                      SERVICE    REQUEST       ID
------------------------  ---------  ------------  --------
Thu Dec 11 16:48:14 2014  compute    RunInstances  7e85d33a
Wed Dec 10 16:00:52 2014  compute    RunInstances  820b3e4f
Wed Dec 10 14:50:22 2014  compute    RunInstances  8a2902f2
Wed Dec 10 14:42:18 2014  compute    RunInstances  9780ef9c
Wed Dec 10 14:11:59 2014  compute    RunInstances  078c410a
Wed Dec 10 12:30:18 2014  compute    RunInstances  e1eb66af
Wed Dec 10 12:25:26 2014  compute    RunInstances  46ae6377
Wed Dec 10 12:24:14 2014  compute    RunInstances  4395f064</codeblock>

  <p>The <codeph>euca-req-history</codeph> tool searches for the requests in the
    <codeph>cloud-requests.log</codeph> log file. In this example, we pass in the name of the
   account ("bob"), and the name of the specific request (<codeph>RunInstance</codeph>) and see that
   the most recent request ID is <b>7e85d33a</b>.</p>
  <p>The LogTracker tools include the <codeph>euca-req-track</codeph> command, which uses
    <codeph>ssh</codeph> to aggregate logs from the distributed Eucalyptus components and sorts them
   according to order of execution. </p>
  <note>You must have ssh access to the machines running the Eucalyptus components for
    <codeph>euca-req-track</codeph> to function properly.</note>
  <p>We can now use this ID with the <codeph>euca-req-track</codeph> command to search across all of
   the Eucalyptus component logs for error entries matching that ID:</p>
  <codeblock>[root@c-27 ~]# euca-req-track 7e85d33a --ssh
info: Make sure Eucalyptus logs are in /opt/eucalyptus/var/log/eucalyptus/ of euca hosts
info: log files are copied to /tmp/tmpAnnGIA/
=======  ==============  ============  ==================  =======  ========================  
ORDER    DATE            HOST          SERVICE             LEVEL    LOCATION                  LOG
=======  ==============  ============  ==================  =======  ========================  
      0  12-11 16:48:14  10.111.1.62   EC2/AS/ELB/OSG/IAM  DEBUG    ComputeService            RunInstancesType:7e85d33a-c9b3-470b-9749-615de2b98ae1:return=true:epoch=null:sta
      0                                                                                       tus=null
      0  12-11 16:48:15  10.111.1.62   EC2/AS/ELB/OSG/IAM  DEBUG    ComputeService            RunInstancesResponseType:7e85d33a-c9b3-470b-9749-615de2b98ae1:return=true:epoch=
      0                                                                                       null:status=null
      1  12-11 16:48:15  10.111.1.62   EC2/AS/ELB/OSG/IAM  INFO     AdmissionControl          Found authorized clusters: [CC_71]
 ......
......
      3  12-11 16:48:26  10.111.1.118  NC                  ERROR    InitWSSEC                 could not initialize policy file /opt/eucalyptus/usr/share/eucalyptus/policies/s
      3                                                                                       c-client-policy.xml
      3  12-11 16:48:26  10.111.1.118  NC                  ERROR    scClientCall              Error initializing WSSEC state for SC Client
      3  12-11 16:48:26  10.111.1.118  NC                  ERROR    scExportVolumeStub        operation on 10.111.1.71 could not be invoked (check SC host, port, and credenti
      3                                                                                       als)
      3  12-11 16:48:26  10.111.1.118  NC                  DEBUG    scClientCall              done scOps=ExportVolume clientrc=0 opFail=1
      3  12-11 16:48:26  10.111.1.118  NC                  ERROR    connect_ebs_volume        Failed to get connection information for volume vol-28d85101 from storage contro
      3                                                                                       ller at: http://10.111.1.71:8773/services/Storage
      3  12-11 16:48:26  10.111.1.118  NC                  ERROR    iqn_creator               [i-a42445ab] failed to attach volume during VBR construction for vda
      3  12-11 16:48:26  10.111.1.118  NC                  ERROR    art_implement_tree        [i-a42445ab] failed to create artifact iscsi-vol (error=1, may retry) on try 1
=======  ==============  ============  ==================  =======  ========================  
</codeblock>
  <p>In this case, Bob's RunInstances command is not successful because there's a missing policy
   file on the NC. </p>
 </conbody>

</concept>
